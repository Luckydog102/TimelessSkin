from typing import Dict, List, Any, Optional
import json
import os
from datetime import datetime
from ..models.embedding_model import EmbeddingModel

import numpy as np
import faiss
from pathlib import Path
from collections import defaultdict
import logging

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

class KnowledgeManager:
    """ç»Ÿä¸€çš„çŸ¥è¯†åº“ç®¡ç†æ¨¡å—ï¼Œä½¿ç”¨ embedding_model + FAISS å®Œæˆå‘é‡æ£€ç´¢"""

    def __init__(self, config: Dict[str, Any], embedding_model: EmbeddingModel):
        self.config = config
        self.embedding_model = embedding_model
        self.vector_index = None
        self.embeddings_matrix = None
        self.documents = []
        self.metadata_index = defaultdict(list)
        self.cache = {}
        self._initialized = False
        self.initialize()

    def initialize(self) -> None:
        """åˆå§‹åŒ–çŸ¥è¯†åº“"""
        try:
            if not self._initialized:
                self._load_knowledge()
                self._build_index()
                self._initialized = True
                logger.info("çŸ¥è¯†åº“åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            # è®¾ç½®ä¸ºåˆå§‹åŒ–çŠ¶æ€ï¼Œä½†å…è®¸ç³»ç»Ÿç»§ç»­è¿è¡Œ
            self._initialized = True

    def _load_knowledge(self) -> None:
        """åŠ è½½çŸ¥è¯†åº“æ–‡ä»¶"""
        try:
            # ä½¿ç”¨ç›¸å¯¹è·¯å¾„
            base_path = Path(os.path.join(os.path.dirname(os.path.dirname(__file__)), "knowledge"))
            logger.info(f"åŠ è½½çŸ¥è¯†åº“è·¯å¾„: {base_path}")
            
            # å¦‚æœå·²ç»åŠ è½½è¿‡ï¼Œç›´æ¥è¿”å›
            if self.documents:
                return
                
            for subfolder, category in [("skin_conditions", "skin_conditions"),
                                         ("products", "products"),
                                         ("skincare_rules", "skincare_rules")]:
                path = base_path / subfolder
                if path.exists():
                    for file in path.glob("*.json"):
                        try:
                            with open(file, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                                self._process_document(data, category)
                        except Exception as e:
                            logger.error(f"åŠ è½½æ–‡ä»¶å¤±è´¥ {file}: {e}")
                else:
                    logger.warning(f"çŸ¥è¯†åº“å­ç›®å½•ä¸å­˜åœ¨: {path}")
                    
            logger.info(f"æˆåŠŸåŠ è½½ {len(self.documents)} ä¸ªæ–‡æ¡£")
        except Exception as e:
            logger.error(f"åŠ è½½çŸ¥è¯†åº“å¤±è´¥: {e}")
            # ç¡®ä¿å³ä½¿åŠ è½½å¤±è´¥ï¼Œä¹Ÿèƒ½ç»§ç»­è¿è¡Œ
            pass

    def _process_document(self, data: Dict[str, Any], category: str) -> None:
        content = self._extract_content(data)
        metadata = self._extract_metadata(data, category)

        doc = {
            "content": content,
            "metadata": metadata,
            "category": category,
            "source": data.get("source", "unknown"),
            "timestamp": datetime.now().isoformat()
        }
        self.documents.append(doc)

        for key, value in metadata.items():
            values = value if isinstance(value, list) else [value]
            for v in values:
                self.metadata_index[f"{key}:{v}"].append(len(self.documents) - 1)

    def _extract_content(self, data: Dict[str, Any]) -> str:
        def flatten(d: Any) -> List[str]:
            if isinstance(d, dict):
                parts = []
                for v in d.values():
                    parts.extend(flatten(v))
                return parts
            elif isinstance(d, list):
                parts = []
                for item in d:
                    parts.extend(flatten(item))
                return parts
            elif isinstance(d, (str, int, float)):
                return [str(d)]
            return []

        text_parts = flatten(data)
        return " ".join(text_parts)

    def _extract_metadata(self, data: Dict[str, Any], category: str) -> Dict[str, Any]:
        metadata = {"category": category}
        if category == "skin_conditions":
            metadata.update({
                "condition_type": data.get("condition"),
                "severity": list(data.get("severity_levels", {}).keys()),
                "related_conditions": data.get("related_conditions", [])
            })
        elif category == "products":
            metadata.update({
                "product_type": data.get("category"),
                "suitable_for": data.get("suitable_for", []),
                "ingredients": data.get("ingredients", [])
            })
        return metadata

    def _build_index(self) -> None:
        """æ„å»ºå‘é‡ç´¢å¼•ï¼Œæ·»åŠ é”™è¯¯å¤„ç†å’Œç©ºæ£€æŸ¥"""
        try:
            if not self.documents:
                logger.warning("æ²¡æœ‰æ–‡æ¡£å¯ç´¢å¼•ï¼Œè·³è¿‡ç´¢å¼•æ„å»º")
                # åˆ›å»ºä¸€ä¸ªç©ºçš„ç´¢å¼•ï¼Œé¿å…åç»­æœç´¢é”™è¯¯
                self.vector_index = faiss.IndexFlatL2(768)  # ä½¿ç”¨BGEæ¨¡å‹çš„é»˜è®¤ç»´åº¦
                self.embeddings_matrix = np.zeros((0, 768), dtype='float32')
                return

            texts = [doc["content"] for doc in self.documents]
            logger.info(f"å¼€å§‹ä¸º {len(texts)} ä¸ªæ–‡æ¡£ç”ŸæˆåµŒå…¥å‘é‡")
            
            try:
                # ç”ŸæˆåµŒå…¥å‘é‡
                embeddings = self.embedding_model.predict(texts)
                
                # æ£€æŸ¥æ˜¯å¦æˆåŠŸè·å–åµŒå…¥å‘é‡
                if embeddings is None or len(embeddings) == 0:
                    logger.error("è·å–åµŒå…¥å‘é‡å¤±è´¥ï¼Œä½¿ç”¨ç©ºçŸ©é˜µ")
                    self.embeddings_matrix = np.zeros((len(texts), 768), dtype='float32')
                    self.vector_index = faiss.IndexFlatL2(768)
                    return
                    
                # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œç¡®ä¿æ˜¯2Dæ•°ç»„
                if isinstance(embeddings, list):
                    if not embeddings or not isinstance(embeddings[0], (list, np.ndarray)):
                        logger.error("åµŒå…¥å‘é‡æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨ç©ºçŸ©é˜µ")
                        self.embeddings_matrix = np.zeros((len(texts), 768), dtype='float32')
                        self.vector_index = faiss.IndexFlatL2(768)
                        return
                        
                    self.embeddings_matrix = np.array(embeddings).astype('float32')
                else:
                    logger.error("åµŒå…¥å‘é‡ä¸æ˜¯åˆ—è¡¨æ ¼å¼ï¼Œä½¿ç”¨ç©ºçŸ©é˜µ")
                    self.embeddings_matrix = np.zeros((len(texts), 768), dtype='float32')
                    self.vector_index = faiss.IndexFlatL2(768)
                    return
                
                # æ£€æŸ¥åµŒå…¥çŸ©é˜µçš„å½¢çŠ¶
                if len(self.embeddings_matrix.shape) != 2:
                    logger.error(f"åµŒå…¥çŸ©é˜µç»´åº¦é”™è¯¯: {self.embeddings_matrix.shape}")
                    self.embeddings_matrix = np.zeros((len(texts), 768), dtype='float32')
                    self.vector_index = faiss.IndexFlatL2(768)
                    return
                    
                dimension = self.embeddings_matrix.shape[1]
                logger.info(f"åµŒå…¥å‘é‡ç»´åº¦: {dimension}")
                
                self.vector_index = faiss.IndexFlatL2(dimension)
                self.vector_index.add(self.embeddings_matrix)
                logger.info("ç´¢å¼•æ„å»ºæˆåŠŸ")
                
            except Exception as e:
                logger.error(f"ç”ŸæˆåµŒå…¥å‘é‡å¤±è´¥: {e}")
                self.embeddings_matrix = np.zeros((len(texts), 768), dtype='float32')
                self.vector_index = faiss.IndexFlatL2(768)
            
        except Exception as e:
            logger.error(f"æ„å»ºç´¢å¼•å¤±è´¥: {e}")
            # åˆ›å»ºä¸€ä¸ªç©ºçš„ç´¢å¼•ï¼Œé¿å…åç»­æœç´¢é”™è¯¯
            self.embeddings_matrix = np.zeros((0, 768), dtype='float32')
            self.vector_index = faiss.IndexFlatL2(768)

    def search(self,
               query: str,
               category: Optional[str] = None,
               metadata_filters: Optional[Dict[str, Any]] = None,
               top_k: int = 5,
               use_cache: bool = True) -> List[Dict[str, Any]]:
        """æœç´¢çŸ¥è¯†åº“"""
        try:
            # ç¡®ä¿å·²åˆå§‹åŒ–
            if not self._initialized:
                self.initialize()

            # ä½¿ç”¨æ›´ç»†ç²’åº¦çš„ç¼“å­˜key
            cache_key = f"{query}:{category}:{str(metadata_filters)}:{top_k}"
            if use_cache and cache_key in self.cache:
                return self.cache[cache_key]

            # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£å’Œç´¢å¼•
            if not self.documents or self.vector_index is None:
                logger.warning("çŸ¥è¯†åº“ä¸ºç©ºæˆ–ç´¢å¼•æœªæ„å»ºï¼Œè¿”å›ç©ºç»“æœ")
                return []

            # åº”ç”¨è¿‡æ»¤å™¨
            filtered_indices = set(range(len(self.documents)))
            if category:
                filtered_indices &= set(self.metadata_index.get(f"category:{category}", []))
                
            if metadata_filters:
                for key, value in metadata_filters.items():
                    values = value if isinstance(value, list) else [value]
                    for v in values:
                        filtered_indices &= set(self.metadata_index.get(f"{key}:{v}", []))

            # å‘é‡æ£€ç´¢
            query_vec = self.embedding_model.predict(query)
            if not query_vec:
                logger.error("æŸ¥è¯¢å‘é‡ç”Ÿæˆå¤±è´¥")
                return []
                
            if isinstance(query_vec[0], list):
                query_vec_np = np.array(query_vec).astype('float32')
            else:
                query_vec_np = np.array([query_vec]).astype('float32')

            distances, indices = self.vector_index.search(query_vec_np, min(top_k * 2, len(self.documents)))
            results = []
            seen = set()

            for idx, dist in zip(indices[0], distances[0]):
                if 0 <= idx < len(self.documents) and idx in filtered_indices and idx not in seen:
                    doc = self.documents[idx].copy()
                    doc["similarity_score"] = float(1 / (1 + dist))
                    results.append(doc)
                    seen.add(idx)

            results = sorted(results, key=lambda x: x["similarity_score"], reverse=True)[:top_k]

            # æ›´æ–°ç¼“å­˜
            if use_cache:
                self.cache[cache_key] = results

            return results
        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {e}")
            return []

    def update_knowledge(self, new_documents: List[Dict[str, Any]]) -> None:
        for doc in new_documents:
            self._process_document(doc, doc.get("category", "unknown"))
        self._build_index()
        self._save_knowledge()

    def _save_knowledge(self) -> None:
        try:
            # ä½¿ç”¨ç›¸å¯¹è·¯å¾„
            kb_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "knowledge", "metadata", "index.json")
            os.makedirs(os.path.dirname(kb_path), exist_ok=True)
            with open(kb_path, 'w', encoding='utf-8') as f:
                json.dump({
                    "documents": self.documents,
                    "last_updated": datetime.now().isoformat()
                }, f, ensure_ascii=False, indent=2)
            logger.info(f"çŸ¥è¯†åº“ä¿å­˜æˆåŠŸ: {kb_path}")
        except Exception as e:
            logger.error(f"ä¿å­˜çŸ¥è¯†åº“å¤±è´¥: {e}")

    def get_knowledge_stats(self) -> Dict[str, Any]:
        return {
            "total_documents": len(self.documents),
            "categories": {
                cat: len([d for d in self.documents if d["category"] == cat])
                for cat in set(d["category"] for d in self.documents)
            },
            "metadata_types": list(set(k.split(":")[0] for k in self.metadata_index)),
            "last_updated": self.documents[-1]["timestamp"] if self.documents else None
        }
    
if __name__=="__main__":
    config = {
        "knowledge_base": {
            "path": "src/knowledge"
        }
    }

    # åˆå§‹åŒ– embedding + RAG
    embedding_model = EmbeddingModel()
    embedding_model.initialize()

    rag = KnowledgeManager(config, embedding_model)

    # æµ‹è¯•æŸ¥è¯¢
    query = "è„¸ä¸Šé•¿ç—˜ï¼Œæœ‰çº¢è‚¿å’Œç—˜å°ï¼Œæƒ³æ‰¾ç¥›ç—˜äº§å“"
    results = rag.search(query, top_k=3)

    print("ğŸ” æœç´¢ç»“æœï¼š")
    for i, doc in enumerate(results, 1):
        print(f"\nğŸ“„ ç»“æœ {i}")
        print(f"æ¥æº: {doc['source']}")
        print(f"ç›¸ä¼¼åº¦åˆ†æ•°: {doc['similarity_score']:.4f}")
        print(f"å†…å®¹é¢„è§ˆ: {doc['content'][:80]}...")